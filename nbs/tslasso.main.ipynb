{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b75c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tslasso.main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "from montlake.atomgeom.features import get_features,get_D_feats_feats\n",
    "from montlake.atomgeom.utils import get_atoms_4\n",
    "from montlake.simulations.rigidethanol import get_rigid_ethanol_data\n",
    "from montlake.utils.utils import get_234_indices, get_atoms3_full, get_atoms4_full, data_stream_custom_range, get_cosines\n",
    "from montlake.geometry.geometry import get_geom, get_wlpca_tangent_sel, get_rm_tangent_sel\n",
    "from montlake.statistics.normalization import normalize_L212\n",
    "from montlake.optimization.gradientgrouplasso import get_sr_lambda_parallel\n",
    "from montlake.optimization.utils import get_selected_function_ids,get_selected_functions_lm2\n",
    "from montlake.utils.replicates import Replicate, get_supports_brute_tslasso,get_supports_lasso\n",
    "\n",
    "from megaman.embedding import SpectralEmbedding\n",
    "\n",
    "import dill as pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations,combinations\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pathos\n",
    "from pathos.multiprocessing import ProcessingPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "def run_exp(positions, hparams):\n",
    "\n",
    "    d = hparams.d \n",
    "    n_components = hparams.n_components\n",
    "    atoms2_feat = hparams.atoms2_feat \n",
    "    atoms3_feat = hparams.atoms3_feat\n",
    "    atoms4_feat = hparams.atoms4_feat\n",
    "    atoms2_dict = hparams.atoms2_dict\n",
    "    atoms3_dict = hparams.atoms3_dict\n",
    "    atoms4_dict = hparams.atoms4_dict\n",
    "    diagram = hparams.diagram\n",
    "\n",
    "    ii = np.asarray(hparams.ii)\n",
    "    jj = np.asarray(hparams.jj)\n",
    "    outfile = hparams.outdir + '/' + hparams.name + 'results_tslasso' \n",
    "    #load geometric features\n",
    "    natoms = positions.shape[1]\n",
    "    n = positions.shape[0]\n",
    "    atoms2 = np.asarray(list(itertools.combinations(range(natoms), 2))) \n",
    "    atoms2full = atoms2\n",
    "    atoms3 = np.asarray(list(itertools.combinations(range(natoms), 3))) \n",
    "    atoms4 = np.asarray(list(itertools.combinations(range(natoms), 4))) \n",
    "    atoms3full = get_atoms3_full(atoms3)\n",
    "    atoms4full = get_atoms4_full(atoms4)\n",
    "    \n",
    "    if atoms2_feat:\n",
    "        atoms2_feats = atoms2full\n",
    "    else:\n",
    "        atoms2_feats = np.asarray([])\n",
    "        \n",
    "    if atoms3_feat:\n",
    "        atoms3_feats = atoms3full\n",
    "    else:\n",
    "        atoms3_feats = np.asarray([])\n",
    "        \n",
    "    if atoms4_feat:\n",
    "        atoms4_feats = atoms4full\n",
    "    else:\n",
    "        atoms4_feats = np.asarray([])\n",
    "            \n",
    "    #compute rotation/translation invariant featureization\n",
    "    cores = pathos.multiprocessing.cpu_count() - 1\n",
    "    pool = Pool(cores)\n",
    "    print('feature dimensions',atoms2_feats.shape, atoms3_feats.shape,atoms4_feats.shape)\n",
    "    #import pdb;pdb.set_trace\n",
    "    results = pool.map(lambda i: get_features(positions[i],\n",
    "                               atoms2 = atoms2_feats,\n",
    "                               atoms3 = atoms3_feats,\n",
    "                               atoms4 = atoms4_feats),\n",
    "        data_stream_custom_range(list(range(n))))\n",
    "    data = np.vstack([np.hstack(results[i]) for i in range(n)])\n",
    "    data = data - np.mean(data, axis = 0)\n",
    "    \n",
    "    #apply SVD\n",
    "    svd = TruncatedSVD(n_components=50)\n",
    "    data_svd = svd.fit_transform(data)\n",
    "    \n",
    "    \n",
    "    #compute geometry\n",
    "    radius = hparams.radius\n",
    "    n_neighbors = hparams.n_neighbors\n",
    "    geom = get_geom(data_svd, radius, n_neighbors) \n",
    "\n",
    "    print('computing embedding (for comparison)')\n",
    "    spectral_embedding = SpectralEmbedding(n_components=n_components,eigen_solver='arpack',geom=geom)\n",
    "    embed_spectral = spectral_embedding.fit_transform(data_svd)\n",
    "    embedding = embed_spectral\n",
    "    \n",
    "    #obtain gradients\n",
    "    if atoms2_dict:\n",
    "        atoms2_dicts = atoms2full\n",
    "    else:\n",
    "        atoms2_dicts = np.asarray([])\n",
    "    if atoms3_dict:\n",
    "        atoms3_dicts = atoms3full\n",
    "    else:\n",
    "        atoms3_dicts = np.asarray([])\n",
    "    if atoms4_dict and not diagram:\n",
    "        atoms4_dicts = atoms4full\n",
    "    elif atoms4_dict:\n",
    "        atoms4_dicts= get_atoms_4(natoms, ii, jj)[0]\n",
    "    else:\n",
    "        atoms4_dicts = np.asarray([])\n",
    "        \n",
    "    p = len(atoms2_dicts) + len(atoms3_dicts) + len(atoms4_dicts)\n",
    "    #get gradients\n",
    "    replicates = {}\n",
    "    nreps = hparams.nreps\n",
    "    nsel = hparams.nsel\n",
    "    for r in range(nreps):\n",
    "        #print(i)\n",
    "        replicates[r] = Replicate(nsel = nsel, n = 10000)\n",
    "        replicates[r].tangent_bases_M = get_wlpca_tangent_sel(data_svd, geom, replicates[r].selected_points, d)\n",
    "        D_feats_feats = np.asarray([get_D_feats_feats(positions[replicates[r].selected_points[i]],\n",
    "                   atoms2in = atoms2_feats, \n",
    "                   atoms3in = atoms3_feats, \n",
    "                   atoms4in = atoms4_feats, \n",
    "                   atoms2out = atoms2_dicts, \n",
    "                   atoms3out = atoms3_dicts,\n",
    "                   atoms4out = atoms4_dicts) for i in range(nsel)])\n",
    "        replicates[r].dg_x = np.asarray([svd.transform(D_feats_feats[i].transpose()).transpose() for i in range(nsel)])\n",
    "        replicates[r].dg_x_normalized = normalize_L212(replicates[r].dg_x)\n",
    "        replicates[r].dg_M = np.einsum('i b p, i b d -> i d p', replicates[r].dg_x_normalized, replicates[r].tangent_bases_M)\n",
    "     \n",
    "    \n",
    "    #run ts lasso\n",
    "    gl_itermax= hparams.gl_itermax\n",
    "    reg_l2 = hparams.reg_l2\n",
    "    max_search = hparams.max_search\n",
    "    d = hparams.d\n",
    "    tol = hparams.tol\n",
    "    learning_rate = hparams.learning_rate\n",
    "    for r in range(nreps):\n",
    "        replicates[r].results = get_sr_lambda_parallel(np.asarray([np.identity(d) for i in range(nsel)]), replicates[r].dg_M, gl_itermax,reg_l2, max_search, d, tol,learning_rate)\n",
    "        replicates[r].get_ordered_axes()\n",
    "        replicates[r].sel_l = replicates[r].get_selection_lambda()\n",
    "\n",
    "    #get manifold lasso support\n",
    "    selected_functions_unique = np.asarray(np.unique(get_selected_function_ids(replicates,d)), dtype = int)\n",
    "    support_tensor_lasso, supports_lasso = get_supports_lasso(replicates,p,d)\n",
    "\n",
    "    #get two stage support\n",
    "    selected_functions_lm2 = get_selected_functions_lm2(replicates)\n",
    "    support_tensor_ts, supports_ts  = get_supports_brute_tslasso(replicates,nreps,p,d,selected_functions_lm2)\n",
    "    selected_functions_unique_twostage  = np.asarray(np.unique(supports_ts), dtype = int)#np.unique(np.asarray(np.where(support_tensor_ts > 0.)[0], dtype = int))\n",
    "\n",
    "    pool.close()\n",
    "    pool.restart()\n",
    "    \n",
    "    #compute function values for plotting... needs 'order234' for full computation\n",
    "    print('computing selected function values lasso, ' + str(selected_functions_unique))\n",
    "    selected_function_values = pool.map(\n",
    "                    lambda i: get_features(positions[i],\n",
    "                                           atoms2 = np.asarray([]),\n",
    "                                           atoms3 = np.asarray([]),\n",
    "                                           atoms4 = atoms4_dicts[selected_functions_unique]),\n",
    "                    data_stream_custom_range(list(range(n))))\n",
    "\n",
    "    selected_function_values_array = np.vstack([np.hstack(selected_function_values[i]) for i in range(n)])\n",
    "\n",
    "    print('computing selected function values two stage, ' + str(selected_functions_unique_twostage))\n",
    "    selected_function_values_brute = pool.map(\n",
    "                    lambda i: get_features(positions[i],\n",
    "                                           atoms2 = np.asarray([]),\n",
    "                                           atoms3 = np.asarray([]),\n",
    "                                           atoms4 = atoms4_dicts[selected_functions_unique_twostage]),\n",
    "                    data_stream_custom_range(list(range(n))))\n",
    "\n",
    "    selected_function_values_array_brute = np.vstack([np.hstack(selected_function_values_brute[i]) for i in range(n)])\n",
    "    \n",
    "    #remove large gradient arrays\n",
    "    print('prep save')\n",
    "    replicates_small = {}\n",
    "    for r in range(nreps):\n",
    "        replicates_small[r] = Replicate(nsel=nsel, n=n,\n",
    "                                        selected_points=replicates[r].selected_points)\n",
    "        replicates_small[r].dg_M = replicates[r].dg_M\n",
    "        replicates_small[r].cs_reorder = replicates[r].cs_reorder\n",
    "        replicates_small[r].xaxis_reorder = replicates[r].xaxis_reorder\n",
    "        \n",
    "    print('getting cosines')\n",
    "    cosine = get_cosines(replicates[0].dg_M)\n",
    "    replicates_small[0].cosine_abs = np.mean(np.abs(cosine), axis = 0)\n",
    "    \n",
    "    #prepare to save\n",
    "    results = {}\n",
    "    results['replicates_small'] = replicates_small\n",
    "    results['data'] = data_svd\n",
    "    results['embed'] = embedding\n",
    "    results['supports_ts'] = support_tensor_ts, supports_ts\n",
    "    results['supports_lasso'] = support_tensor_lasso, supports_lasso\n",
    "    results['supports_lasso_values'] = selected_function_values\n",
    "    results['supports_ts_values'] = selected_function_values_brute\n",
    "    results['selected_lasso'] = selected_functions_unique\n",
    "    results['selected_ts'] = selected_functions_unique_twostage\n",
    "    results['geom'] = geom\n",
    "    results['dictionary'] = {}\n",
    "    results['dictionary']['atoms2'] = atoms2_dicts\n",
    "    results['dictionary']['atoms3'] = atoms3_dicts\n",
    "    results['dictionary']['atoms4'] = atoms4_dicts\n",
    "    \n",
    "    #save\n",
    "    with open(outfile,'wb') as output:\n",
    "        pickle.dump(results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10eefc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uberduck-ml-dev",
   "language": "python",
   "name": "uberduck-ml-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
