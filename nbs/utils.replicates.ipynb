{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924df56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82434044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "from itertools import combinations, permutations\n",
    "from montlake.statistics.basispursuit import get_basispursuit_losses\n",
    "\n",
    "def get_detected_values2d(subset, supports,nreps):\n",
    "    \n",
    "    detected_values = np.zeros((subset.shape[0],subset.shape[0]))\n",
    "    nreps = len(list(supports.keys()))\n",
    "    for r in range(nreps):\n",
    "        i1 = np.where(subset == int(supports[r][0]))[0]\n",
    "        i2 = np.where(subset == int(supports[r][1]))[0]\n",
    "        detected_values[i1,i2] += 1\n",
    "        detected_values[i2,i1] += 1\n",
    "    \n",
    "    detected_values = np.asarray(np.where(detected_values > 0))\n",
    "    return(detected_values)\n",
    "\n",
    "def get_support_indices2d(sup_set, sup_sel,nreps):\n",
    "    \n",
    "    #toplot = np.zeros(np.repeat(sup_set.shape[0], d ))\n",
    "    toplot = np.zeros((sup_set.shape[0],sup_set.shape[0]))\n",
    "    for r in range(nreps):\n",
    "        i1 = np.where(sup_set == sup_sel[r][0])[0]\n",
    "        i2 = np.where(sup_set == sup_sel[r][1])[0]\n",
    "        toplot[i1,i2] += 1\n",
    "        toplot[i2,i1] += 1   \n",
    "    return(toplot)\n",
    "\n",
    "# def get_supports(nreps,p,d, selected_functions):\n",
    "#     for r in range(nreps):\n",
    "#         subset_associator = np.asarray(list(enumerate(selected_functions_lm2[r])))\n",
    "#         sub_sets = list(combinations(subset_associator[:,0], d))\n",
    "#         full_sets = list(combinations(subset_associator[:,1], d))\n",
    "#         basispursuit_losses_subset = get_basispursuit_losses(replicates[r].dg_M[:,:,selected_functions_lm2[r]],replicates[r].dphispectral_M_normalized)\n",
    "#         for s in range(len(full_sets)):\n",
    "#             ols_norms[r][full_sets[s]] = basispursuit_losses_subset[sub_sets[s]]\n",
    "#         ind = np.unravel_index(np.nanargmin(ols_norms[r], axis=None), ols_norms[r].shape)\n",
    "#         toadd = list(permutations(ind,2))\n",
    "#         for s in range(len(toadd)):\n",
    "#             supports[toadd[s]] += 1    \n",
    "\n",
    "def supportlist_to_tensor(supports,p ):\n",
    "    d = supports.shape[1]\n",
    "    nreps = supports.shape[0]\n",
    "    support_tensor = np.zeros(np.repeat(p,d))\n",
    "    for r in range(nreps):\n",
    "        toadd = np.asarray(list(permutations(supports[r],d)))\n",
    "        for s in range(len(toadd)):\n",
    "            support_tensor[tuple(np.asarray(toadd[s], dtype = int))] += 1\n",
    "    return(support_tensor)\n",
    "\n",
    "def get_supports_lasso(replicates, p,d):\n",
    "    \n",
    "    nreps = len(list(replicates.keys()))\n",
    "    supports = np.zeros((nreps, d))\n",
    "    for r in range(nreps):\n",
    "        supports[r] = np.where(np.linalg.norm(replicates[r].results[1][replicates[r].results[0]], axis = tuple([0,2])) > 0)[0]\n",
    "    support_tensor = supportlist_to_tensor(supports,p )\n",
    "    return(support_tensor,supports)\n",
    "\n",
    "def get_supports_brute(replicates,nreps,p,d,selected_functions_lm2):\n",
    "    \n",
    "    ols_norms= np.zeros(tuple(np.concatenate([[nreps], np.repeat(p,d)])))\n",
    "    supports = np.zeros((nreps, d), dtype = int)\n",
    "    ols_norms[:] = np.nan\n",
    "    for r in range(nreps):\n",
    "        subset_associator = np.asarray(list(enumerate(selected_functions_lm2[r])))\n",
    "        sub_sets = list(combinations(subset_associator[:,0], d))\n",
    "        full_sets = list(combinations(subset_associator[:,1], d))\n",
    "        basispursuit_losses_subset = get_basispursuit_losses(replicates[r].dg_M[:,:,selected_functions_lm2[r]],replicates[r].dphispectral_M_normalized)\n",
    "        for s in range(len(full_sets)):\n",
    "            ols_norms[r][full_sets[s]] = basispursuit_losses_subset[sub_sets[s]]\n",
    "        supports[r] = np.unravel_index(np.nanargmin(ols_norms[r], axis=None), ols_norms[r].shape)\n",
    "    support_tensor = supportlist_to_tensor(supports,p )\n",
    "    return(support_tensor, supports)\n",
    "\n",
    "def get_supports_brute_tslasso(replicates,nreps,p,d,selected_functions_lm2):\n",
    "    \n",
    "    nsel = replicates[0].dg_M.shape[0]\n",
    "    ols_norms= np.zeros(tuple(np.concatenate([[nreps], np.repeat(p,d)])))\n",
    "    supports = np.zeros((nreps, d), dtype = int)\n",
    "    ols_norms[:] = np.nan\n",
    "    for r in range(nreps):\n",
    "        subset_associator = np.asarray(list(enumerate(selected_functions_lm2[r])))\n",
    "        sub_sets = list(combinations(subset_associator[:,0], d))\n",
    "        full_sets = list(combinations(subset_associator[:,1], d))\n",
    "        basispursuit_losses_subset = get_basispursuit_losses(replicates[r].dg_M[:,:,selected_functions_lm2[r]],np.asarray([np.identity(d) for i in range(nsel)]))\n",
    "        for s in range(len(full_sets)):\n",
    "            ols_norms[r][full_sets[s]] = basispursuit_losses_subset[sub_sets[s]]\n",
    "        supports[r] = np.unravel_index(np.nanargmin(ols_norms[r], axis=None), ols_norms[r].shape)\n",
    "    support_tensor = supportlist_to_tensor(supports,p )\n",
    "    return(support_tensor,supports)\n",
    "\n",
    "\n",
    "\n",
    "class Replicate():\n",
    "\n",
    "    def __init__(self, nsel = None, n = None, selected_points = None):\n",
    "\n",
    "        self.nsel = nsel\n",
    "        if selected_points is not None:\n",
    "            self.selected_points = selected_points\n",
    "        else:\n",
    "            self.selected_points = np.random.choice(list(range(n)), nsel, replace=False)\n",
    "\n",
    "\n",
    "    def get_ordered_axes(self):\n",
    "        replicate = self\n",
    "        cs = rearrange(np.asarray(list(replicate.results[1].values())), 'l n p m -> l m n p')\n",
    "        xaxis = np.asarray(np.asarray(list(replicate.results[1].keys())))\n",
    "        xaxis_reorder = xaxis[xaxis.argsort()]\n",
    "        cs_reorder = cs[xaxis.argsort()]\n",
    "        xaxis_reorder = xaxis[xaxis.argsort()]\n",
    "        replicate.cs = cs\n",
    "        replicate.cs_reorder = cs_reorder\n",
    "        replicate.xaxis_reorder = xaxis_reorder\n",
    "        replicate.xaxis = xaxis\n",
    "\n",
    "    def get_selection_lambda(self):\n",
    "\n",
    "        replicate = self\n",
    "        lambdas = np.asarray(list(replicate.results[1].keys()))\n",
    "        lambdas.sort()\n",
    "        sel_l = np.where(lambdas ==  replicate.results[0])[0][0]\n",
    "        return(sel_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d678d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifold_env_april",
   "language": "python",
   "name": "manifold_env_april"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
