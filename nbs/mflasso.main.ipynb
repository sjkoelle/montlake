{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mflasso.main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f15970a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "from montlake.atomgeom.features import get_features,get_D_feats_feats\n",
    "from montlake.atomgeom.utils import get_atoms_4\n",
    "from montlake.simulations.rigidethanol import get_rigid_ethanol_data\n",
    "from montlake.utils.utils import get_234_indices, get_atoms3_full, get_atoms4_full, data_stream_custom_range, get_cosines\n",
    "from montlake.geometry.geometry import get_geom, get_wlpca_tangent_sel, get_rm_tangent_sel\n",
    "from montlake.gradients.estimate import get_grads_pullback\n",
    "from montlake.statistics.normalization import normalize_L212\n",
    "from montlake.optimization.gradientgrouplasso import get_sr_lambda_parallel\n",
    "from montlake.optimization.utils import get_selected_function_ids,get_selected_functions_lm2\n",
    "from montlake.utils.replicates import Replicate, get_supports_brute,get_supports_lasso\n",
    "\n",
    "from megaman.embedding import SpectralEmbedding\n",
    "\n",
    "import dill as pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import permutations,combinations\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pathos\n",
    "from pathos.multiprocessing import ProcessingPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407b4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "def run_exp(positions, hparams):\n",
    "\n",
    "    d = hparams.d \n",
    "    n_components = hparams.n_components\n",
    "    atoms2_feat = hparams.atoms2_feat \n",
    "    atoms3_feat = hparams.atoms3_feat\n",
    "    atoms4_feat = hparams.atoms4_feat\n",
    "    atoms2_dict = hparams.atoms2_dict\n",
    "    atoms3_dict = hparams.atoms3_dict\n",
    "    atoms4_dict = hparams.atoms4_dict\n",
    "    diagram = hparams.diagram\n",
    "\n",
    "    ii = np.asarray(hparams.ii)\n",
    "    jj = np.asarray(hparams.jj)\n",
    "    outfile = hparams.outdir + '/' + hparams.name + 'results_mflasso' \n",
    "    print('loading geometric features')\n",
    "    natoms = positions.shape[1]\n",
    "    n = positions.shape[0]\n",
    "    atoms2 = np.asarray(list(itertools.combinations(range(natoms), 2))) \n",
    "    atoms2full = atoms2\n",
    "    atoms3 = np.asarray(list(itertools.combinations(range(natoms), 3))) \n",
    "    atoms4 = np.asarray(list(itertools.combinations(range(natoms), 4))) \n",
    "    atoms3full = get_atoms3_full(atoms3)\n",
    "    atoms4full = get_atoms4_full(atoms4)\n",
    "    \n",
    "    if atoms2_feat:\n",
    "        atoms2_feats = atoms2full\n",
    "    else:\n",
    "        atoms2_feats = np.asarray([])\n",
    "        \n",
    "    if atoms3_feat:\n",
    "        atoms3_feats = atoms3full\n",
    "    else:\n",
    "        atoms3_feats = np.asarray([])\n",
    "        \n",
    "    if atoms4_feat:\n",
    "        atoms4_feats = atoms4full\n",
    "    else:\n",
    "        atoms4_feats = np.asarray([])\n",
    "            \n",
    "    print('computing featurization')\n",
    "    cores = pathos.multiprocessing.cpu_count() - 1\n",
    "    pool = Pool(cores)\n",
    "    print('feature dimensions 234',atoms2_feats.shape, atoms3_feats.shape,atoms4_feats.shape)\n",
    "    \n",
    "    results = pool.map(lambda i: get_features(positions[i],\n",
    "                               atoms2 = atoms2_feats,\n",
    "                               atoms3 = atoms3_feats,\n",
    "                               atoms4 = atoms4_feats),\n",
    "        data_stream_custom_range(list(range(n))))\n",
    "    data = np.vstack([np.hstack(results[i]) for i in range(n)])\n",
    "    data = data - np.mean(data, axis = 0)\n",
    "    svd = TruncatedSVD(n_components=50)\n",
    "    data_svd = svd.fit_transform(data)\n",
    "    \n",
    "    print('computing geometry')\n",
    "    radius = hparams.radius\n",
    "    n_neighbors = hparams.n_neighbors\n",
    "    geom = get_geom(data_svd, radius, n_neighbors) \n",
    "    \n",
    "    print('computing embedding')\n",
    "    spectral_embedding = SpectralEmbedding(n_components=n_components,eigen_solver='arpack',geom=geom)\n",
    "    embed_spectral = spectral_embedding.fit_transform(data_svd)\n",
    "    \n",
    "    print('getting gradients')\n",
    "    if atoms2_dict:\n",
    "        atoms2_dicts = atoms2full\n",
    "    else:\n",
    "        atoms2_dicts = np.asarray([])\n",
    "    if atoms3_dict:\n",
    "        atoms3_dicts = atoms3full\n",
    "    else:\n",
    "        atoms3_dicts = np.asarray([])\n",
    "    if atoms4_dict and not diagram:\n",
    "        atoms4_dicts = atoms4full\n",
    "    elif atoms4_dict:\n",
    "        atoms4_dicts= get_atoms_4(natoms, ii, jj)[0]\n",
    "    else:\n",
    "        atoms4_dicts = np.asarray([])  \n",
    "    p = len(atoms2_dicts) + len(atoms3_dicts) + len(atoms4_dicts)\n",
    "    replicates = {}\n",
    "    embedding = embed_spectral\n",
    "    nreps = hparams.nreps\n",
    "    nsel = hparams.nsel\n",
    "    for r in range(nreps):\n",
    "        replicates[r] = Replicate(nsel = nsel, n = 10000)\n",
    "        replicates[r].tangent_bases_M = get_wlpca_tangent_sel(data_svd, geom, replicates[r].selected_points, d)\n",
    "        replicates[r].tangent_bases_phi = get_rm_tangent_sel(embedding, geom, replicates[r].selected_points, d)\n",
    "        D_feats_feats = np.asarray([get_D_feats_feats(positions[replicates[r].selected_points[i]],\n",
    "                   atoms2in = atoms2_feats, \n",
    "                   atoms3in = atoms3_feats, \n",
    "                   atoms4in = atoms4_feats, \n",
    "                   atoms2out = atoms2_dicts, \n",
    "                   atoms3out = atoms3_dicts,\n",
    "                   atoms4out = atoms4_dicts) for i in range(nsel)])\n",
    "        replicates[r].dg_x = np.asarray([svd.transform(D_feats_feats[i].transpose()).transpose() for i in range(nsel)])\n",
    "        replicates[r].dg_x_normalized = normalize_L212(replicates[r].dg_x)\n",
    "        replicates[r].dg_M = np.einsum('i b p, i b d -> i d p', replicates[r].dg_x_normalized, replicates[r].tangent_bases_M)\n",
    "        replicates[r].dphispectral_M = get_grads_pullback(data_svd,  embedding, geom, replicates[r].tangent_bases_M, replicates[r].tangent_bases_phi, replicates[r].selected_points)\n",
    "        replicates[r].dphispectral_M_normalized = normalize_L212(replicates[r].dphispectral_M)\n",
    "    \n",
    "    print('running manifold lasso')\n",
    "    gl_itermax= hparams.gl_itermax\n",
    "    reg_l2 = hparams.reg_l2\n",
    "    max_search = hparams.max_search\n",
    "    d = hparams.d\n",
    "    tol = hparams.tol\n",
    "    learning_rate = hparams.learning_rate\n",
    "    for r in range(nreps):\n",
    "        replicates[r].results = get_sr_lambda_parallel(replicates[r].dphispectral_M_normalized , replicates[r].dg_M, gl_itermax,reg_l2, max_search, d, tol,learning_rate)\n",
    "        replicates[r].get_ordered_axes()\n",
    "        replicates[r].sel_l = replicates[r].get_selection_lambda()\n",
    "\n",
    "    print('getting manifold lasso support')\n",
    "    selected_functions_unique = np.asarray(np.unique(get_selected_function_ids(replicates,d)), dtype = int)\n",
    "    support_tensor_lasso, supports_lasso = get_supports_lasso(replicates,p,d)\n",
    "\n",
    "    print('getting two-stage support')\n",
    "    selected_functions_lm2 = get_selected_functions_lm2(replicates)\n",
    "    support_tensor_ts, supports_ts = get_supports_brute(replicates,nreps,p,d,selected_functions_lm2)\n",
    "    selected_functions_unique_twostage  = np.unique(np.asarray(np.where(support_tensor_ts > 0.)[0], dtype = int))\n",
    "\n",
    "    pool.close()\n",
    "    pool.restart()\n",
    "    \n",
    "    #needs 'order234' for full computation\n",
    "    print('computing selected function values lasso, ' + str(selected_functions_unique))\n",
    "    selected_function_values = pool.map(\n",
    "                    lambda i: get_features(positions[i],\n",
    "                                           atoms2 = np.asarray([]),\n",
    "                                           atoms3 = np.asarray([]),\n",
    "                                           atoms4 = atoms4_dicts[selected_functions_unique]),\n",
    "                    data_stream_custom_range(list(range(n))))\n",
    "\n",
    "    selected_function_values_array = np.vstack([np.hstack(selected_function_values[i]) for i in range(n)])\n",
    "\n",
    "    print('computing selected function values two stage, ' + str(selected_functions_unique_twostage))\n",
    "    selected_function_values_ts = pool.map(\n",
    "                    lambda i: get_features(positions[i],\n",
    "                                           atoms2 = np.asarray([]),\n",
    "                                           atoms3 = np.asarray([]),\n",
    "                                           atoms4 = atoms4_dicts[selected_functions_unique_twostage]),\n",
    "                    data_stream_custom_range(list(range(n))))\n",
    "\n",
    "    selected_function_values_array_brute = np.vstack([np.hstack(selected_function_values_ts[i]) for i in range(n)])\n",
    "    \n",
    "    print('remove large gradient arrays for memory efficiency')\n",
    "    replicates_small = {}\n",
    "    for r in range(nreps):\n",
    "        replicates_small[r] = Replicate(nsel=nsel, n=n,\n",
    "                                        selected_points=replicates[r].selected_points)\n",
    "        replicates_small[r].dg_M = replicates[r].dg_M\n",
    "        replicates_small[r].dphispectral_M = replicates[r].dphispectral_M\n",
    "        replicates_small[r].cs_reorder = replicates[r].cs_reorder\n",
    "        replicates_small[r].xaxis_reorder = replicates[r].xaxis_reorder\n",
    "        \n",
    "    print('getting cosines')\n",
    "    cosine = get_cosines(replicates[0].dg_M)\n",
    "    replicates_small[0].cosine_abs = np.mean(np.abs(cosine), axis = 0)\n",
    "    \n",
    "    print('prepare to save')\n",
    "    results = {}\n",
    "    results['replicates_small'] = replicates_small\n",
    "    results['embed'] = embedding\n",
    "    results['geom'] = geom\n",
    "    results['data'] = data_svd\n",
    "    results['supports_ts'] = support_tensor_ts, supports_ts\n",
    "    results['supports_lasso'] = support_tensor_lasso, supports_lasso\n",
    "    results['supports_ts_values'] = selected_function_values_ts\n",
    "    results['supports_lasso_values'] = selected_function_values\n",
    "    results['selected_ts'] = selected_functions_unique_twostage \n",
    "    results['selected_lasso'] = selected_functions_unique\n",
    "    results['dictionary'] = {}\n",
    "    results['dictionary']['atoms2'] = atoms2_dicts\n",
    "    results['dictionary']['atoms3'] = atoms3_dicts\n",
    "    results['dictionary']['atoms4'] = atoms4_dicts\n",
    "\n",
    "    print('saving')\n",
    "    with open(outfile,'wb') as output:\n",
    "        pickle.dump(results, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manifold_env_april",
   "language": "python",
   "name": "manifold_env_april"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
